{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-16T09:41:50.711227Z","iopub.execute_input":"2022-02-16T09:41:50.711600Z","iopub.status.idle":"2022-02-16T09:41:50.741209Z","shell.execute_reply.started":"2022-02-16T09:41:50.711501Z","shell.execute_reply":"2022-02-16T09:41:50.740461Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Процесс тренировки простой нейронной сети","metadata":{}},{"cell_type":"code","source":"# Функция сигмоида\n# Необходима для определения весов\ndef sigmoid(x,der = False):\n    if der:\n        return x*(1-x)\n    return 1/(1+np.exp(-x))\n\n\n# Набор входных данных. У нас 4 списка, это значит, что получится 4 нейрона в первом слое\n\nx = np.array([[1,0,1],   # Описанме самого действия: - Если мы будем передавать первый список, то ожидаем получить 0\n             [1,0,1],    # - Если мы будем передавать второй список, то ожидаем получить 0\n             [0,1,0],    # - третий список, то ожидаем получить 1\n             [0,1,0]])  # - четвертый список, то ожидаем получить 1\n\n\n\n# Указываем выходные или ожидаемые данные\n#  прописываем список. Т (функция переноса) и выполняем функцию переноса, чтобы получить 1 столбец и 4 ряда\n\ny = np.array([[0,0,1,1]]).T\n\n\n# Чтобы случайное распределение было одинаковым (каждый раз). Это позволит проще отслеживать работу сети после внесения изменений\n\nnp.random.seed(1)\n\n\n# Иницифлизируем веса случайным образом cо средним 0\n# syn0 - означает (синопс zero). Т.к у нас два слоя (вход и выход), то нам нужна одна матрица весов, которая их свяжет\n# ее размерность 3х1 (т.к. у нас есть 3 столбца в первом списке и 1 столбец во втором).\n# значения устанавливаются случайным образом\n\nsyn0 = 2 * np.random.random((3,1))-1\n\n\n\n# Далее идет процесс обучения (будет 100000 циклов)\n# Мы позволяем сети предсказать вывод на основе ввода\n# В процессе обучения перемножаются веса на входные значения. Далее сверка с результатом и проверка ( На сколько мы ошиблись?)\n# После этого - перемножение с наклоном сигмоида и последний этап это - обновление весов\n\nL1 = []\nfor iter in range(100000):\n    L0 = x                                    # Прямое распространение\n    L1 = sigmoid( np.dot(L0, syn0))\n    L1_error = y - L1                         #  На сколько мы ошиблись?\n    L1_delta = L1_error * sigmoid(L1, True)   # Перемножим с наклоном сигмоиды; на основе значений L1\n    syn0 += np.dot(L0.T, L1_delta)            # Обновим веса\n    \nprint(\"Выходные данные после тренировки: \")\nprint(L1)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T11:49:47.917323Z","iopub.execute_input":"2022-02-16T11:49:47.917613Z","iopub.status.idle":"2022-02-16T11:49:49.832473Z","shell.execute_reply.started":"2022-02-16T11:49:47.917578Z","shell.execute_reply":"2022-02-16T11:49:49.831598Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Выходные данные после тренировки: (10000 циклов)\n[[0.00355991]\n [0.00355991]\n [0.99494968]\n [0.99494968]]           \n \n ### Результаты  максимально приближенны к входным данным","metadata":{}},{"cell_type":"markdown","source":"### Чем больше будет циклов, тем обучение и результат будут более точны\n### Выходные данные после тренировки: (100000 циклов)\n[[0.00112051]\n [0.00112051]\n [0.99841385]\n [0.99841385]]","metadata":{}},{"cell_type":"markdown","source":"# Test (проверка)","metadata":{}},{"cell_type":"code","source":"# Передаем новый список. Обучение нам дало, то что программа понимает, что когда мы передаем  new1 список [1,0,1] - программа поставит число 0\n\nnew1 = np.array([1,0,1])\nL1_new = sigmoid(np.dot(new1, syn0))\n\nprint(\"new1 - новые данные: \")\nprint(L1_new)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:21:23.115774Z","iopub.execute_input":"2022-02-16T12:21:23.116308Z","iopub.status.idle":"2022-02-16T12:21:23.123340Z","shell.execute_reply.started":"2022-02-16T12:21:23.116258Z","shell.execute_reply":"2022-02-16T12:21:23.122636Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# если передается  new2 список [0,1,0] - программа поставит 1\nnew2 = np.array([0,1,0])\nL1_new = sigmoid(np.dot(new2, syn0))\n\nprint(\"new2 - новые данные: \")\nprint(L1_new)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:26:58.639552Z","iopub.execute_input":"2022-02-16T12:26:58.640523Z","iopub.status.idle":"2022-02-16T12:26:58.648447Z","shell.execute_reply.started":"2022-02-16T12:26:58.640482Z","shell.execute_reply":"2022-02-16T12:26:58.647388Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Передадим значение, которое не было при обучении: new3 список [1,1,1]\nnew3 = np.array([1,1,1])\nL1_new = sigmoid(np.dot(new3, syn0))\n\nprint(\"new3 - новые данные: \")\nprint(L1_new)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:41:30.940828Z","iopub.execute_input":"2022-02-16T12:41:30.941147Z","iopub.status.idle":"2022-02-16T12:41:30.948565Z","shell.execute_reply.started":"2022-02-16T12:41:30.941113Z","shell.execute_reply":"2022-02-16T12:41:30.947694Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Передадим значение, которое не было при обучении: new4 список [0,0,0]\nnew4 = np.array([0,0,0])\nL1_new = sigmoid(np.dot(new4, syn0))\n\nprint(\"new4 - новые данные: \")\nprint(L1_new)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:48:32.354784Z","iopub.execute_input":"2022-02-16T12:48:32.355245Z","iopub.status.idle":"2022-02-16T12:48:32.361292Z","shell.execute_reply.started":"2022-02-16T12:48:32.355192Z","shell.execute_reply":"2022-02-16T12:48:32.360595Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Мы создали 2 слоя.\n## В первом слое - 4 нейрона (входные данные). Каждый нейрон представлен определенным списком.\n## Второй слой - это выходные данные.\n\n## Мы обучили нейронную сеть.\n### Обучение нам дало, то что программа понимает, что когда мы передаем  new1 список [1,0,1] - программа поставит число 0\n### new1 - новые данные: \n[0.00112051]\n### если передается  new2 список [0,1,0] - программа поставит 1\n### new2 - новые данные: \n[0.99841385]\n###  Передадим значение, которое не было при обучении: new3 список [1,1,1]\n###  new3 - новые данные: \n[0.41386949]\n### Передадим значение, которое не было при обучении: new4 список [0,0,0]\n### new4 - новые данные: \n[0.5]\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}