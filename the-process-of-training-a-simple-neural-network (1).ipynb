{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-16T13:52:17.694359Z","iopub.execute_input":"2022-02-16T13:52:17.694792Z","iopub.status.idle":"2022-02-16T13:52:17.729844Z","shell.execute_reply.started":"2022-02-16T13:52:17.694693Z","shell.execute_reply":"2022-02-16T13:52:17.729319Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Процесс тренировки простой нейронной сети","metadata":{}},{"cell_type":"code","source":"# Функция сигмоида\n# Необходима для определения весов\ndef sigmoid(x,der = False):\n    if der:\n        return x*(1-x)\n    return 1/(1+np.exp(-x))\n\n\n# Набор входных данных. У нас 4 списка, это значит, что получится 4 нейрона в первом слое\n\nx = np.array([[1,0,1],   # Описанме самого действия: - Если мы будем передавать первый список, то ожидаем получить 0\n             [1,0,1],    # - Если мы будем передавать второй список, то ожидаем получить 0\n             [0,1,0],    # - третий список, то ожидаем получить 1\n             [0,1,0]])  # - четвертый список, то ожидаем получить 1\n\n\n\n# Указываем выходные или ожидаемые данные\n#  прописываем список. Т (функция переноса) и выполняем функцию переноса, чтобы получить 1 столбец и 4 ряда\n\ny = np.array([[0,0,1,1]]).T\n\n\n# Чтобы случайное распределение было одинаковым (каждый раз). Это позволит проще отслеживать работу сети после внесения изменений\n\nnp.random.seed(1)\n\n\n# Иницифлизируем веса случайным образом cо средним 0\n# syn0 - означает (синопс zero). Т.к у нас два слоя (вход и выход), то нам нужна одна матрица весов, которая их свяжет\n# ее размерность 3х1 (т.к. у нас есть 3 столбца в первом списке и 1 столбец во втором).\n# значения устанавливаются случайным образом\n\nsyn0 = 2 * np.random.random((3,1))-1\n\n\n\n# Далее идет процесс обучения (будет 100000 циклов)\n# Мы позволяем сети предсказать вывод на основе ввода\n# В процессе обучения перемножаются веса на входные значения. Далее сверка с результатом и проверка ( На сколько мы ошиблись?)\n# После этого - перемножение с наклоном сигмоида и последний этап это - обновление весов\n\nL1 = []\nfor iter in range(100000):\n    L0 = x                                    # Прямое распространение\n    L1 = sigmoid( np.dot(L0, syn0))\n    L1_error = y - L1                         #  На сколько мы ошиблись?\n    L1_delta = L1_error * sigmoid(L1, True)   # Перемножим с наклоном сигмоиды; на основе значений L1\n    syn0 += np.dot(L0.T, L1_delta)            # Обновим веса\n    \nprint(\"Выходные данные после тренировки: \")\nprint(L1)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:52:24.385479Z","iopub.execute_input":"2022-02-16T13:52:24.385779Z","iopub.status.idle":"2022-02-16T13:52:25.853764Z","shell.execute_reply.started":"2022-02-16T13:52:24.385753Z","shell.execute_reply":"2022-02-16T13:52:25.852557Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### Выходные данные после тренировки: (10000 циклов)\n[[0.00355991]\n [0.00355991]\n [0.99494968]\n [0.99494968]]           \n \n ### Результаты  максимально приближенны к входным данным Чем больше будет циклов, тем обучение и результат будут более точны","metadata":{}},{"cell_type":"markdown","source":"\n### Выходные данные после тренировки: (100000 циклов)\n[[0.00112051]\n [0.00112051]\n [0.99841385]\n [0.99841385]]","metadata":{}},{"cell_type":"markdown","source":"# Test (проверка)","metadata":{}},{"cell_type":"code","source":"# Передаем новый список. Обучение нам дало, то что программа понимает, что когда мы передаем  new1 список [1,0,1] - программа поставит число 0\n\nnew1 = np.array([1,0,1])\nL1_new = sigmoid(np.dot(new1, syn0))\n\nprint(\"new1 - новые данные: \")\nprint(L1_new)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:52:36.269634Z","iopub.execute_input":"2022-02-16T13:52:36.270073Z","iopub.status.idle":"2022-02-16T13:52:36.275834Z","shell.execute_reply.started":"2022-02-16T13:52:36.270030Z","shell.execute_reply":"2022-02-16T13:52:36.275199Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# если передается  new2 список [0,1,0] - программа поставит 1\nnew2 = np.array([0,1,0])\nL1_new = sigmoid(np.dot(new2, syn0))\n\nprint(\"new2 - новые данные: \")\nprint(L1_new)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:52:39.416317Z","iopub.execute_input":"2022-02-16T13:52:39.416587Z","iopub.status.idle":"2022-02-16T13:52:39.424550Z","shell.execute_reply.started":"2022-02-16T13:52:39.416561Z","shell.execute_reply":"2022-02-16T13:52:39.423160Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Передадим значение, которое не было при обучении: new3 список [1,1,1]\nnew3 = np.array([1,1,1])\nL1_new = sigmoid(np.dot(new3, syn0))\n\nprint(\"new3 - новые данные: \")\nprint(L1_new)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:52:42.302420Z","iopub.execute_input":"2022-02-16T13:52:42.303522Z","iopub.status.idle":"2022-02-16T13:52:42.309357Z","shell.execute_reply.started":"2022-02-16T13:52:42.303461Z","shell.execute_reply":"2022-02-16T13:52:42.308703Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Передадим значение, которое не было при обучении: new4 список [0,0,0]\nnew4 = np.array([0,0,0])\nL1_new = sigmoid(np.dot(new4, syn0))\n\nprint(\"new4 - новые данные: \")\nprint(L1_new)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:52:48.390025Z","iopub.execute_input":"2022-02-16T13:52:48.390392Z","iopub.status.idle":"2022-02-16T13:52:48.398715Z","shell.execute_reply.started":"2022-02-16T13:52:48.390362Z","shell.execute_reply":"2022-02-16T13:52:48.396812Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Процесс тренировки простой нейронной сети\n\nВ этом проекте я создала 2 слоя. В первом слое - 4 нейрона (входные данные). Каждый нейрон представлен определенным списком. Второй слой - это выходные данные. Я обучила нейронную сеть. Обучение дало, то что программа понимает, что если передается new1 список [1,0,1] - программа поставит число 0; результат -new1 - новые данные:[0.00112051]. Если передается new2 список [0,1,0] - программа поставит 1; результат new2 - новые данные:[0.99841385] Если передается значение, которое не было при обучении: new4 список [0,0,0], то получится результат: - new4 - новые данные: [0.5]","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}